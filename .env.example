# Decentralized Sequencer Environment Variables
# Copy this file to .env and configure as needed
#
# ⚠️ CRITICAL: PROTOCOL PARAMETERS IN PRODUCTION
# ================================================
# In production/mainnet deployments, the following parameters
# MUST be sourced from on-chain contracts and CANNOT be overridden by env vars:
#   - Submission window duration
#   - Finalization thresholds
#   - Consensus voting thresholds
#   - Validator stake requirements
#   - Batch processing parameters
#
# Environment variables for these parameters are PROVIDED FOR TESTING ONLY.
# The production sequencer will ALWAYS read these values from:
#   - Protocol State Contract
#   - Data Market Contracts
#
# This ensures protocol consistency and prevents individual validators
# from manipulating consensus parameters.
#
# SAFE TO CONFIGURE VIA ENV VARS:
#   ✅ Sequencer ID, P2P port, Redis connection
#   ✅ Component toggles (enable/disable features)
#   ✅ Worker counts and parallelization settings
#   ✅ Storage provider configuration (IPFS, etc.)
#   ✅ RPC endpoints and network settings
#   ✅ Logging and monitoring preferences

# ============================================
# CORE CONFIGURATION
# ============================================

# Unique identifier for this sequencer instance
SEQUENCER_ID=unified-sequencer-1

# P2P port for libp2p networking
P2P_PORT=9001

# Redis configuration (required for dequeuer functionality)
REDIS_HOST=redis            # Use 'redis' for Docker, 'localhost' for local binary
REDIS_PORT=6379            # Port number
REDIS_DB=0                 # Database number (0-15)
REDIS_PASSWORD=            # Password (leave empty if no auth)
PUBLIC_IP=                  # Public IP of the instance where you are running this

# ============================================
# P2P NETWORK CONFIGURATION
# ============================================

# Connection manager settings
CONN_MANAGER_LOW_WATER=100   # Minimum number of connections to maintain
CONN_MANAGER_HIGH_WATER=400  # Maximum number of connections before pruning

# Bootstrap node multiaddr (REQUIRED for P2P)
# Format: /ip4/<IP>/tcp/<PORT>/p2p/<PEER_ID>
# Example: /ip4/YOUR.SERVER.IP.HERE/tcp/9100/p2p/YOUR_PEER_ID_HERE
BOOTSTRAP_MULTIADDR=

# Rendezvous point for peer discovery (REQUIRED for finding other peers)
# This must match what other peers are using
RENDEZVOUS_POINT=powerloom-snapshot-sequencer-network

# Private key for P2P identity (optional - will generate if not provided)
# Format: hex-encoded Ed25519 private key
# Leave empty to generate a new key on each start
PRIVATE_KEY=

# ============================================
# COMPONENT TOGGLES
# ============================================

# Enable/disable individual components (true/false)
ENABLE_LISTENER=true           # P2P gossipsub listener
ENABLE_DEQUEUER=true           # Redis queue processor
ENABLE_FINALIZER=true          # Batch finalizer
ENABLE_BATCH_AGGREGATION=true  # P2P exchange and aggregation of finalized batches
ENABLE_EVENT_MONITOR=false     # Event monitor for EpochReleased events

# ============================================
# BATCH AGGREGATION CONFIGURATION
# ============================================
# ⚠️ IMPORTANT: These values are for TESTING ONLY!
# In production/mainnet, ALL aggregation parameters MUST be read from:
#   - Protocol State Contract
#   - Data Market Contracts
# Environment variables CANNOT override on-chain parameters in production

# Batch aggregation parameters (TESTING ONLY - mainnet reads from contracts)
VOTING_THRESHOLD=0.67      # Percentage of validators required for consensus (67%)
MIN_VALIDATORS=3           # Minimum number of validators for valid consensus
CONSENSUS_TIMEOUT=300      # Timeout for consensus voting in seconds (5 minutes)
CONSENSUS_INTERVAL=60      # How often to check consensus status

# Validator settings (TESTING ONLY - mainnet reads from contracts)
VALIDATOR_STAKE_THRESHOLD=1000    # Minimum POWER tokens required to be a validator
VALIDATOR_MAX_STAKE=100000        # Maximum stake considered for voting weight

# Consensus monitoring and logging
CONSENSUS_LOGGING_LEVEL=info      # Logging detail for consensus process
CONSENSUS_METRICS_ENABLED=true    # Enable detailed metrics for consensus tracking

# ============================================
# WORKER CONFIGURATION
# ============================================
# ⚠️ NOTE: Finalization thresholds and batch parameters are sourced from
# contracts in production. These env values are for testing only.

# Number of dequeuer workers (parallel submission processors)
# NOTE: Now supports multiple submission formats (single & P2PSnapshotSubmission)
DEQUEUER_WORKERS=5

# Number of finalizer workers (parallel batch processors)
# Workers now support camelCase data models and batch processing
FINALIZER_WORKERS=5

# Batch size for parallel finalization (projects per batch part)
# Supports flexible batch sizes for high and low volume epochs
FINALIZATION_BATCH_SIZE=20

# Conversion strategy for submission format (default: auto-detect)
# Options: 'auto' (recommended), 'single', 'batch'
SUBMISSION_FORMAT_STRATEGY=auto

# ============================================
# DEQUEUER CONFIGURATION
# ============================================

# For Docker Compose scaling (number of dequeuer containers)
DEQUEUER_REPLICAS=3

# ============================================
# FINALIZER CONFIGURATION 
# (ONLY NEEDED IF ENABLE_FINALIZER=true)
# ============================================
# The finalizer component handles batch finalization and storage
# These settings are inherited from the centralized sequencer
# and are NOT needed for basic submission listening/processing

# Number of finalizer instances (for redundancy)
FINALIZER_REPLICAS=2

# Storage provider: ipfs, arweave, filecoin
# NOTE: Requires corresponding storage service to be running
STORAGE_PROVIDER=ipfs

# IPFS node address (ONLY if using IPFS for finalized batch storage)
# You need to run an IPFS node separately if finalizer is enabled
# Accepts multiple formats:
#   Simple: 127.0.0.1:5001 or 172.29.0.2:5001
#   URL: http://127.0.0.1:5001
#   Multiaddr: /ip4/127.0.0.1/tcp/5001
#
# For Docker with external IPFS: Run ./setup-docker-network.sh first
# Then use the IP shown by: docker inspect root-ipfs-1 -f '{{index .NetworkSettings.Networks "dsv-internal-network" "IPAddress"}}'
IPFS_HOST=127.0.0.1:5001

# Data availability layer: none, eigenda, celestia, avail
# For future integration with DA layers
DA_PROVIDER=none

# ============================================
# BLOCKCHAIN CONFIGURATION
# ============================================

# Powerloom Protocol Chain RPC Configuration
# All RPC interactions in this component are with the Powerloom chain only
# Option 1: Comma-separated (recommended - simplest)
POWERLOOM_RPC_NODES=http://localhost:8545,http://localhost:8546
# Option 2: JSON array with QUOTED URLs (must use quotes!)
#POWERLOOM_RPC_NODES='["http://localhost:8545","http://localhost:8546"]'

# Powerloom Archive nodes for historical queries (optional, JSON array)
POWERLOOM_ARCHIVE_RPC_NODES=[]

# Source Chain RPC Configuration (JSON array)
# where data is sourced from (e.g., Ethereum, Polygon)
SOURCE_RPC_NODES=["https://eth-mainnet.g.alchemy.com/v2/YOUR_API_KEY","https://mainnet.infura.io/v3/YOUR_KEY"]

# Source Archive nodes (optional, JSON array)
SOURCE_ARCHIVE_RPC_NODES=[]

# Protocol State Contract (REQUIRED for event monitoring)
PROTOCOL_STATE_CONTRACT=0xE88E5f64AEB483d7057645326AdDFA24A3B312DF

# Data Market Addresses (JSON array or comma-separated)
# These are the markets this sequencer will monitor
# Option 1: Comma-separated (recommended - simplest)
DATA_MARKET_ADDRESSES=0x0C2E22fe7526fAeF28E7A58c84f8723dEFcE200c
# Option 2: Multiple markets comma-separated
#DATA_MARKET_ADDRESSES=0x0C2E22fe7526fAeF28E7A58c84f8723dEFcE200c,0x21cb57C1f2352ad215a463DD867b838749CD3b8f
# Option 3: JSON array with QUOTED addresses (must use quotes around addresses!)
#DATA_MARKET_ADDRESSES='["0x0C2E22fe7526fAeF28E7A58c84f8723dEFcE200c","0x21cb57C1f2352ad215a463DD867b838749CD3b8f"]'

# ============================================
# EVENT MONITORING CONFIGURATION
# ============================================

# Path to the Protocol State Contract ABI JSON file
# This file contains the ABI for parsing EpochReleased events
CONTRACT_ABI_PATH=./abi/ProtocolContract.json

# Submission window duration in seconds (how long to accept submissions after epoch)
# ⚠️ TESTING ONLY: In production, this MUST be read from Protocol State Contract
# This env var is ONLY for local testing/development
# Production deployments will IGNORE this value and use on-chain parameters
SUBMISSION_WINDOW_DURATION=60

# Maximum concurrent submission windows
MAX_CONCURRENT_WINDOWS=100

# Event polling interval in seconds
EVENT_POLL_INTERVAL=12

# Starting block for event monitoring 
# 0 = start from current block (recommended for production)
# Any positive number = start from that specific block
EVENT_START_BLOCK=0

# Number of blocks to process in batch
EVENT_BLOCK_BATCH_SIZE=1000

# ============================================
# IDENTITY & VERIFICATION
# ============================================

# Full node addresses (JSON array or comma-separated)
# These addresses bypass certain verification checks by the dequeuer
FULL_NODE_ADDRESSES=

# Skip identity verification (for testing only)
SKIP_IDENTITY_VERIFICATION=false

# Check for flagged snapshotters
CHECK_FLAGGED_SNAPSHOTTERS=true

# Verification cache TTL in seconds
VERIFICATION_CACHE_TTL=600


# ============================================
# DEDUPLICATION CONFIGURATION
# ============================================

# Enable deduplication
DEDUP_ENABLED=true

# Local cache size for deduplication
DEDUP_LOCAL_CACHE_SIZE=10000

# Deduplication TTL in seconds
DEDUP_TTL_SECONDS=7200

# ============================================
# PERFORMANCE TUNING
# ============================================

# Connection manager settings
CONN_MANAGER_LOW_WATER=100
CONN_MANAGER_HIGH_WATER=400

# Gossipsub heartbeat interval in milliseconds
GOSSIPSUB_HEARTBEAT_MS=700

# Maximum submissions per epoch
MAX_SUBMISSIONS_PER_EPOCH=100

# ============================================
# DEBUGGING & MONITORING
# ============================================

# Enable debug logging (true/false)
DEBUG_MODE=false
LOG_LEVEL=info

# Metrics port for Prometheus
METRICS_PORT=9090
METRICS_ENABLED=false

# Slack webhook for alerts (optional)
SLACK_WEBHOOK_URL=

# Enable advanced pipeline health monitoring
# Provides more detailed alerts and tracking for batch processing stages
PIPELINE_HEALTH_MONITORING=false

# API configuration
API_HOST=0.0.0.0
API_PORT=8080
API_AUTH_TOKEN=

# ============================================
# QUICK START CONFIGURATIONS
# ============================================

# For LOCAL TESTING (everything on one machine):
# - Use defaults above
# - Set REDIS_ADDR=localhost:6379
# - Leave PRIVATE_KEY empty (will auto-generate)
# - Set DEBUG_MODE=true

# For DOCKER COMPOSE:
# - Set REDIS_ADDR=redis:6379
# - Set IPFS_HOST=ipfs:5001
# - Use the bootstrap multiaddr above

# For PRODUCTION:
# - Generate unique PRIVATE_KEY for each instance
# - Set proper RPC_URL with your API key
# - Set DEBUG_MODE=false
# - Configure STORAGE_PROVIDER and DA_PROVIDER as needed