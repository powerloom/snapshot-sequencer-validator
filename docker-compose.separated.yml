services:
  redis:
    image: redis:8-alpine
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes --maxmemory 2gb
    ports:
      - "${REDIS_BIND_PORT:-6379}:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    networks:
      - sequencer-net

  # P2P Gateway - Singleton for ALL P2P communication
  p2p-gateway:
    build:
      context: .
      dockerfile: Dockerfile.p2p-gateway
    environment:
      - SEQUENCER_ID=p2p-gateway-${SEQUENCER_ID:-1}
      - P2P_PORT=${P2P_PORT:-9001}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=${REDIS_DB:-0}
      - REDIS_PASSWORD=${REDIS_PASSWORD:-}
      - BOOTSTRAP_MULTIADDR=${BOOTSTRAP_MULTIADDR}
      - RENDEZVOUS_POINT=${RENDEZVOUS_POINT:-powerloom-snapshot-sequencer-network}
      - PRIVATE_KEY=${PRIVATE_KEY}
      - PUBLIC_IP=${PUBLIC_IP}
      - DEBUG_MODE=${DEBUG_MODE:-false}
      # Protocol/Market config
      - PROTOCOL_STATE_CONTRACT=${PROTOCOL_STATE_CONTRACT}
      - DATA_MARKET_ADDRESSES=${DATA_MARKET_ADDRESSES}
    depends_on:
      redis:
        condition: service_healthy
    ports:
      - "${P2P_PORT:-9001}:${P2P_PORT:-9001}"
    networks:
      - sequencer-net
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Dequeuer - Processes submissions from Redis queue (scalable)
  dequeuer:
    build:
      context: .
      dockerfile: Dockerfile.snapshot-sequencer
    environment:
      - SEQUENCER_ID=dequeuer-${SEQUENCER_ID:-1}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=${REDIS_DB:-0}
      - REDIS_PASSWORD=${REDIS_PASSWORD:-}
      - DEBUG_MODE=${DEBUG_MODE:-false}
      # Component toggles - ONLY DEQUEUER
      - ENABLE_LISTENER=false
      - ENABLE_DEQUEUER=true
      - ENABLE_FINALIZER=false
      - ENABLE_BATCH_AGGREGATION=false
      - ENABLE_EVENT_MONITOR=false
      # Dequeuer specific
      - DEQUEUER_WORKERS=${DEQUEUER_WORKERS:-5}
      - MAX_SUBMISSIONS_PER_EPOCH=${MAX_SUBMISSIONS_PER_EPOCH:-100}
      # Identity verification
      - SKIP_IDENTITY_VERIFICATION=${SKIP_IDENTITY_VERIFICATION:-false}
      - CHECK_FLAGGED_SNAPSHOTTERS=${CHECK_FLAGGED_SNAPSHOTTERS:-true}
      - VERIFICATION_CACHE_TTL=${VERIFICATION_CACHE_TTL:-600}
      # Protocol/Market config
      - PROTOCOL_STATE_CONTRACT=${PROTOCOL_STATE_CONTRACT}
      - DATA_MARKET_ADDRESSES=${DATA_MARKET_ADDRESSES}
      - POWERLOOM_RPC_NODES=${POWERLOOM_RPC_NODES}
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - sequencer-net
    restart: unless-stopped
    deploy:
      replicas: ${DEQUEUER_REPLICAS:-2}
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Event Monitor - Watches for EpochReleased events
  event-monitor:
    build:
      context: .
      dockerfile: Dockerfile.snapshot-sequencer
    environment:
      - SEQUENCER_ID=event-monitor-${SEQUENCER_ID:-1}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=${REDIS_DB:-0}
      - REDIS_PASSWORD=${REDIS_PASSWORD:-}
      - DEBUG_MODE=${DEBUG_MODE:-false}
      # Component toggles - ONLY EVENT MONITOR
      - ENABLE_LISTENER=false
      - ENABLE_DEQUEUER=false
      - ENABLE_FINALIZER=false
      - ENABLE_BATCH_AGGREGATION=false
      - ENABLE_EVENT_MONITOR=true
      # RPC Configuration
      - POWERLOOM_RPC_NODES=${POWERLOOM_RPC_NODES}
      - POWERLOOM_ARCHIVE_RPC_NODES=${POWERLOOM_ARCHIVE_RPC_NODES:-[]}
      # Contract addresses
      - PROTOCOL_STATE_CONTRACT=${PROTOCOL_STATE_CONTRACT}
      - DATA_MARKET_ADDRESSES=${DATA_MARKET_ADDRESSES}
      # Contract ABI path
      - CONTRACT_ABI_PATH=${CONTRACT_ABI_PATH:-./abi/ProtocolContract.json}
      # Event monitoring config
      - EVENT_POLL_INTERVAL=${EVENT_POLL_INTERVAL:-12}
      - EVENT_START_BLOCK=${EVENT_START_BLOCK:-0}
      - EVENT_BLOCK_BATCH_SIZE=${EVENT_BLOCK_BATCH_SIZE:-1000}
      - MAX_CONCURRENT_WINDOWS=${MAX_CONCURRENT_WINDOWS:-100}
      - SUBMISSION_WINDOW_DURATION=${SUBMISSION_WINDOW_DURATION:-60}
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - sequencer-net
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Finalizer - Creates batches, stores in IPFS (scalable)
  finalizer:
    build:
      context: .
      dockerfile: Dockerfile.snapshot-sequencer
    environment:
      - SEQUENCER_ID=finalizer-${SEQUENCER_ID:-1}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=${REDIS_DB:-0}
      - REDIS_PASSWORD=${REDIS_PASSWORD:-}
      - DEBUG_MODE=${DEBUG_MODE:-false}
      # Component toggles - ONLY FINALIZER (NO AGGREGATION)
      - ENABLE_LISTENER=false
      - ENABLE_DEQUEUER=false
      - ENABLE_FINALIZER=true
      - ENABLE_BATCH_AGGREGATION=false  # Aggregation is separate now
      - ENABLE_EVENT_MONITOR=false
      # Storage configuration
      - STORAGE_PROVIDER=${STORAGE_PROVIDER:-ipfs}
      - IPFS_HOST=${IPFS_HOST:-localhost:5001}
      - DA_PROVIDER=${DA_PROVIDER:-none}
      # Protocol/Market config
      - PROTOCOL_STATE_CONTRACT=${PROTOCOL_STATE_CONTRACT}
      - DATA_MARKET_ADDRESSES=${DATA_MARKET_ADDRESSES}
      - SUBMISSION_WINDOW_DURATION=${SUBMISSION_WINDOW_DURATION:-60}
      # Finalizer specific
      - FINALIZER_WORKERS=${FINALIZER_WORKERS:-5}
      - FINALIZATION_BATCH_SIZE=${FINALIZATION_BATCH_SIZE:-20}
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - sequencer-net
    restart: unless-stopped
    deploy:
      replicas: ${FINALIZER_REPLICAS:-2}
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Aggregator - Singleton for consensus/batch aggregation
  aggregator:
    build:
      context: .
      dockerfile: Dockerfile.aggregator
    environment:
      - SEQUENCER_ID=aggregator-${SEQUENCER_ID:-1}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=${REDIS_DB:-0}
      - REDIS_PASSWORD=${REDIS_PASSWORD:-}
      - DEBUG_MODE=${DEBUG_MODE:-false}
      # Storage configuration for aggregated results
      - IPFS_HOST=${IPFS_HOST:-localhost:5001}
      # Protocol/Market config
      - PROTOCOL_STATE_CONTRACT=${PROTOCOL_STATE_CONTRACT}
      - DATA_MARKET_ADDRESSES=${DATA_MARKET_ADDRESSES}
      - POWERLOOM_RPC_NODES=${POWERLOOM_RPC_NODES}
    depends_on:
      redis:
        condition: service_healthy
      p2p-gateway:
        condition: service_started
    networks:
      - sequencer-net
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # State Tracker - Background worker for data aggregation
  state-tracker:
    build:
      context: .
      dockerfile: Dockerfile.state-tracker
    container_name: dsv-state-tracker
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=
      - REDIS_DB=0
      - PROTOCOL=${PROTOCOL:-aave}
      - MARKET=${MARKET:-mainnet}
      - STATE_TRACKER_RETENTION_DAYS=7
      - LOG_LEVEL=${LOG_LEVEL:-info}
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - sequencer-net
    restart: unless-stopped
    profiles:
      - monitoring

  # Monitor API - REST API for pipeline monitoring
  monitor-api:
    build:
      context: .
      dockerfile: docker/Dockerfile.monitor-api
    container_name: dsv-monitor-api
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=${REDIS_DB:-0}
      - REDIS_PASSWORD=${REDIS_PASSWORD:-}
      - MONITOR_API_PORT=${MONITOR_API_PORT:-9091}
      - VALIDATOR_ID=${SEQUENCER_ID:-validator-001}
      - PROTOCOL=${PROTOCOL:-aave}
      - MARKET=${MARKET:-mainnet}
    ports:
      - "${MONITOR_API_PORT:-9091}:${MONITOR_API_PORT:-9091}"
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - sequencer-net
    restart: unless-stopped
    profiles:
      - monitoring

  # Optional: Monitoring with Prometheus + Grafana
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    ports:
      - "9090:9090"
    networks:
      - sequencer-net
    profiles:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    networks:
      - sequencer-net
    profiles:
      - monitoring

volumes:
  redis-data:
  prometheus-data:
  grafana-data:

networks:
  sequencer-net:
    driver: bridge